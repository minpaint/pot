"""
üìä –°–µ—Ä–≤–∏—Å –¥–ª—è –µ–¥–∏–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞/—ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–º–ø–æ—Ä—Ç –∏ —ç–∫—Å–ø–æ—Ä—Ç –∏–∑ –æ–¥–Ω–æ–≥–æ Excel-—Ñ–∞–π–ª–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ª–∏—Å—Ç–∞–º–∏:
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (Position)
- –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ (Employee)
- –û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ (Equipment)

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ Resource –∫–ª–∞—Å—Å—ã –∏–∑ django-import-export.
"""
from typing import Dict, List, Optional, Any
from tablib import Dataset
from django.db import transaction
from django.core.exceptions import ValidationError

from directory.resources.organization_structure import OrganizationStructureResource
from directory.resources.employee import EmployeeResource
from deadline_control.resources.equipment import EquipmentResource
from directory.models import Position, Employee, Organization
from deadline_control.models import Equipment


# –°–ª–æ–≤–∞—Ä—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–º—ë–Ω –ª–∏—Å—Ç–æ–≤ –∏ —Ä–µ—Å—É—Ä—Å–æ–≤
RESOURCE_MAPPING = {
    '–°—Ç—Ä—É–∫—Ç—É—Ä–∞': OrganizationStructureResource,
    '–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏': EmployeeResource,
    '–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ': EquipmentResource,
}

# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ª–∏—Å—Ç—ã (–ø—Ä–∏ –æ—à–∏–±–∫–µ –≤ –Ω–∏—Ö - –æ—Ç–∫–∞—Ç –≤—Å–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏)
CRITICAL_SHEETS = {'–°—Ç—Ä—É–∫—Ç—É—Ä–∞'}

# –ü–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Å—Ç–æ–≤ (–≤–∞–∂–Ω–æ!)
PROCESSING_ORDER = ['–°—Ç—Ä—É–∫—Ç—É—Ä–∞', '–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏', '–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ']


def parse_workbook(file_obj) -> Dict[str, Dataset]:
    """
    –ü–∞—Ä—Å–∏—Ç Excel-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {–∏–º—è_–ª–∏—Å—Ç–∞: Dataset}

    Args:
        file_obj: –§–∞–π–ª–æ–≤—ã–π –æ–±—ä–µ–∫—Ç (UploadedFile)

    Returns:
        Dict[str, Dataset]: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ –ª–∏—Å—Ç–∞–º

    Raises:
        ValidationError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –ª–∏—Å—Ç–æ–≤
    """
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
        file_name = getattr(file_obj, 'name', 'file.xlsx')
        file_format = file_name.split('.')[-1].lower()

        if file_format not in ['xlsx', 'xls']:
            raise ValidationError('–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã XLSX –∏ XLS')

        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        file_content = file_obj.read()
        if hasattr(file_obj, 'seek'):
            file_obj.seek(0)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É–∫–∞–∑–∞—Ç–µ–ª—å –≤ –Ω–∞—á–∞–ª–æ –Ω–∞ —Å–ª—É—á–∞–π –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º openpyxl –¥–ª—è —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–æ–≤
        import openpyxl
        from io import BytesIO

        workbook = openpyxl.load_workbook(BytesIO(file_content), read_only=True, data_only=True)
        sheet_names = workbook.sheetnames

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ –ª–∏—Å—Ç–∞
        found_sheets = [name for name in sheet_names if name in RESOURCE_MAPPING]
        if not found_sheets:
            raise ValidationError(
                f'–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ –ª–∏—Å—Ç–∞. '
                f'–û–∂–∏–¥–∞—é—Ç—Å—è –ª–∏—Å—Ç—ã: {", ".join(RESOURCE_MAPPING.keys())}'
            )

        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –ª–∏—Å—Ç
        datasets = {}
        for sheet_name in found_sheets:
            sheet = workbook[sheet_name]

            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç–∞
            data = []
            for row in sheet.iter_rows(values_only=True):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                if any(cell is not None and str(cell).strip() for cell in row):
                    data.append(row)

            if not data:
                continue  # –ü—É—Å—Ç–æ–π –ª–∏—Å—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

            # –°–æ–∑–¥–∞—ë–º Dataset –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            dataset = Dataset()

            # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if data:
                headers = [str(h) if h is not None else '' for h in data[0]]
                dataset.headers = headers

                # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ - –¥–∞–Ω–Ω—ã–µ
                for row_data in data[1:]:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º None –≤ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                    clean_row = [str(cell) if cell is not None else '' for cell in row_data]
                    dataset.append(clean_row)

            datasets[sheet_name] = dataset

        workbook.close()
        return datasets

    except ValidationError:
        raise
    except Exception as e:
        raise ValidationError(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}')


def dry_run_import(datasets: Dict[str, Dataset], organization: Optional[Organization] = None) -> Dict[str, Any]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∏–º–ø–æ—Ä—Ç–∞ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î

    Args:
        datasets: –°–ª–æ–≤–∞—Ä—å {–∏–º—è_–ª–∏—Å—Ç–∞: Dataset}
        organization: –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                     –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ - –≤ —Ñ–∞–π–ª–µ –º–æ–∂–Ω–æ –Ω–µ —É–∫–∞–∑—ã–≤–∞—Ç—å org_short_name_ru,
                     –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —ç—Ç–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è

    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ª–∏—Å—Ç—É:
        {
            'sheet_name': str,
            'status': 'ok'|'warn'|'error',
            'total_rows': int,
            'errors': List[{'row': int, 'message': str}],
            'result': ImportResult object
        }
    """
    results = []

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ª–∏—Å—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    sorted_sheets = [name for name in PROCESSING_ORDER if name in datasets]

    for sheet_name in sorted_sheets:
        dataset = datasets[sheet_name]
        resource_class = RESOURCE_MAPPING[sheet_name]

        sheet_result = {
            'sheet_name': sheet_name,
            'status': 'ok',
            'total_rows': len(dataset),
            'errors': [],
            'result': None,
        }

        try:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —É–ø—Ä–æ—â—ë–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫)
            _normalize_dataset_headers(dataset, sheet_name)

            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è - –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –µ—ë –≤ —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ org_short_name_ru
            if organization:
                _apply_organization_to_dataset(dataset, organization)

            # –°–æ–∑–¥–∞—ë–º —Ä–µ—Å—É—Ä—Å
            resource = resource_class()

            # –í—ã–ø–æ–ª–Ω—è–µ–º dry_run –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (–¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
            with transaction.atomic():
                result = resource.import_data(dataset, dry_run=True, raise_errors=False)
                sheet_result['result'] = result

                # –°–æ–±–∏—Ä–∞–µ–º –æ—à–∏–±–∫–∏
                if result.has_errors():
                    sheet_result['status'] = 'error'

                    for row_error in result.row_errors():
                        row_number = row_error[0]
                        errors_list = row_error[1]

                        for error in errors_list:
                            sheet_result['errors'].append({
                                'row': row_number,
                                'message': str(error.error)
                            })

                elif result.has_validation_errors():
                    sheet_result['status'] = 'warn'

                    # –°–æ–±–∏—Ä–∞–µ–º validation errors –∏–∑ invalid_rows
                    for invalid_row in result.invalid_rows:
                        row_number = invalid_row.number

                        # –°–æ–±–∏—Ä–∞–µ–º –æ—à–∏–±–∫–∏ –ø–æ –ø–æ–ª—è–º
                        for field_name, error_messages in invalid_row.field_specific_errors.items():
                            for msg in error_messages:
                                sheet_result['errors'].append({
                                    'row': row_number,
                                    'message': f'[{field_name}] {msg}'
                                })

                        # –°–æ–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ –æ—à–∏–±–∫–∏ (–Ω–µ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–µ –∫ –ø–æ–ª—è–º)
                        for msg in invalid_row.non_field_specific_errors:
                            sheet_result['errors'].append({
                                'row': row_number,
                                'message': str(msg)
                            })

                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–∫–∞—Ç (–¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ—Ç –æ—à–∏–±–æ–∫ - —ç—Ç–æ dry_run)
                transaction.set_rollback(True)

        except Exception as e:
            sheet_result['status'] = 'error'
            sheet_result['errors'].append({
                'row': 0,
                'message': f'–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Å—Ç–∞: {str(e)}'
            })

        results.append(sheet_result)

    return {
        'sheets': results,
        'has_errors': any(r['status'] == 'error' for r in results),
        'has_critical_errors': any(
            r['status'] == 'error' and r['sheet_name'] in CRITICAL_SHEETS
            for r in results
        ),
        'ready_for_import': not any(
            (r['status'] == 'error' or (r['status'] == 'warn' and r['sheet_name'] in CRITICAL_SHEETS))
            for r in results
        ),
    }


def _normalize_dataset_headers(dataset: Dataset, sheet_name: str):
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —É–ø—Ä–æ—â—ë–Ω–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏

    Args:
        dataset: Dataset –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        sheet_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ ('–°—Ç—Ä—É–∫—Ç—É—Ä–∞', '–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏', '–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ')
    """
    if not dataset.headers:
        return

    # –°–ª–æ–≤–∞—Ä—å –∞–ª–∏–∞—Å–æ–≤: —É–ø—Ä–æ—â—ë–Ω–Ω–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ ‚Üí –ø–æ–ª–Ω–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ
    ALIASES = {
        '–°—Ç—Ä—É–∫—Ç—É—Ä–∞': {
            'subdivision': 'subdivision_name',
            'department': 'department_name',
        },
        '–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏': {
            'subdivision': 'subdivision_name',
            'department': 'department_name',
            'position': 'position_name',
        },
        '–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ': {
            'subdivision': 'subdivision_name',
            'department': 'department_name',
        },
    }

    if sheet_name not in ALIASES:
        return

    aliases = ALIASES[sheet_name]

    # –ó–∞–º–µ–Ω—è–µ–º —É–ø—Ä–æ—â—ë–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –Ω–∞ –ø–æ–ª–Ω—ã–µ
    new_headers = []
    for header in dataset.headers:
        header_str = str(header).strip() if header else ''
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–ª–∏–∞—Å - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        if header_str in aliases:
            new_headers.append(aliases[header_str])
        else:
            new_headers.append(header)

    dataset.headers = new_headers


def _apply_organization_to_dataset(dataset: Dataset, organization: Organization):
    """
    –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç org_short_name_ru –≤ —Å—Ç—Ä–æ–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞, –µ—Å–ª–∏ –æ–Ω–æ –ø—É—Å—Ç–æ–µ
    –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ—Ç –µ—ë –≤ –Ω–∞—á–∞–ª–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

    Args:
        dataset: Dataset –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        organization: –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏
    """
    if not dataset.headers:
        return

    # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ org_short_name_ru –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë –≤ –Ω–∞—á–∞–ª–æ
    if 'org_short_name_ru' not in dataset.headers:
        # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≤ –Ω–∞—á–∞–ª–æ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        for row_data in dataset._data:
            row_data.insert(0, organization.short_name_ru)

        # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ –Ω–∞—á–∞–ª–æ (–ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö!)
        dataset.headers = ['org_short_name_ru'] + list(dataset.headers)

        return

    # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ —É–∂–µ –µ—Å—Ç—å - –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    org_index = dataset.headers.index('org_short_name_ru')

    # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ dataset._data, —Ç.–∫. dataset.dict - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
    for row_data in dataset._data:
        # row_data - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π
        if org_index < len(row_data):
            # –ï—Å–ª–∏ –ø–æ–ª–µ –ø—É—Å—Ç–æ–µ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã - –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é
            if not row_data[org_index] or not str(row_data[org_index]).strip():
                row_data[org_index] = organization.short_name_ru


@transaction.atomic
def commit_import(datasets: Dict[str, Dataset], organization: Optional[Organization] = None) -> Dict[str, Any]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î (–∞—Ç–æ–º–∞—Ä–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è)

    Args:
        datasets: –°–ª–æ–≤–∞—Ä—å {–∏–º—è_–ª–∏—Å—Ç–∞: Dataset}
        organization: –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                     –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ - –≤ —Ñ–∞–π–ª–µ –º–æ–∂–Ω–æ –Ω–µ —É–∫–∞–∑—ã–≤–∞—Ç—å org_short_name_ru,
                     –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —ç—Ç–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è

    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ª–∏—Å—Ç—É:
        {
            'sheet_name': str,
            'status': 'success'|'error',
            'created': int,
            'updated': int,
            'errors': int,
            'skipped': int,
        }
    """
    results = []

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ª–∏—Å—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    sorted_sheets = [name for name in PROCESSING_ORDER if name in datasets]

    try:
        for sheet_name in sorted_sheets:
            dataset = datasets[sheet_name]
            resource_class = RESOURCE_MAPPING[sheet_name]

            sheet_result = {
                'sheet_name': sheet_name,
                'status': 'success',
                'created': 0,
                'updated': 0,
                'errors': 0,
                'skipped': 0,
            }

            try:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —É–ø—Ä–æ—â—ë–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫)
                _normalize_dataset_headers(dataset, sheet_name)

                # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è - –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –µ—ë –≤ —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ org_short_name_ru
                if organization:
                    _apply_organization_to_dataset(dataset, organization)

                # –°–æ–∑–¥–∞—ë–º —Ä–µ—Å—É—Ä—Å
                resource = resource_class()

                # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–º–ø–æ—Ä—Ç
                result = resource.import_data(dataset, dry_run=False, raise_errors=False)

                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                sheet_result['created'] = result.totals.get('new', 0)
                sheet_result['updated'] = result.totals.get('update', 0)
                sheet_result['errors'] = result.totals.get('error', 0)
                sheet_result['skipped'] = result.totals.get('skip', 0) + result.totals.get('invalid', 0)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏
                if result.has_errors():
                    sheet_result['status'] = 'error'

                    # –ï—Å–ª–∏ —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ª–∏—Å—Ç - –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
                    if sheet_name in CRITICAL_SHEETS:
                        raise ValidationError(
                            f'–ò–º–ø–æ—Ä—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –ª–∏—Å—Ç–µ "{sheet_name}". '
                            f'–û—à–∏–±–æ–∫: {sheet_result["errors"]}'
                        )

                # Validation errors –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç –∏–º–ø–æ—Ä—Ç, –Ω–æ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è
                elif result.has_validation_errors():
                    sheet_result['status'] = 'warning'
                    # –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è, –Ω–æ –∏–º–ø–æ—Ä—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è

            except ValidationError:
                raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º ValidationError –¥–∞–ª—å—à–µ –¥–ª—è –æ—Ç–∫–∞—Ç–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            except Exception as e:
                sheet_result['status'] = 'error'
                sheet_result['errors'] = 1

                # –ï—Å–ª–∏ —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ª–∏—Å—Ç - –ø—Ä–µ—Ä—ã–≤–∞–µ–º
                if sheet_name in CRITICAL_SHEETS:
                    raise ValidationError(
                        f'–ò–º–ø–æ—Ä—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ª–∏—Å—Ç–µ "{sheet_name}": {str(e)}'
                    )

            results.append(sheet_result)

        return {
            'sheets': results,
            'success': all(r['status'] == 'success' for r in results),
            'total_created': sum(r['created'] for r in results),
            'total_updated': sum(r['updated'] for r in results),
            'total_errors': sum(r['errors'] for r in results),
        }

    except ValidationError as e:
        # –û—Ç–∫–∞—Ç—ã–≤–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
        transaction.set_rollback(True)
        return {
            'sheets': results,
            'success': False,
            'error_message': str(e),
        }


def export_all_to_workbook(organization: Optional[Organization] = None) -> bytes:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Ç—Ä–∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –≤ –æ–¥–∏–Ω Excel-—Ñ–∞–π–ª —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ª–∏—Å—Ç–∞–º–∏

    Args:
        organization: –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        bytes: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ Excel-—Ñ–∞–π–ª–∞
    """
    import openpyxl
    from io import BytesIO

    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π workbook
    wb = openpyxl.Workbook()
    wb.remove(wb.active)  # –£–¥–∞–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –ª–∏—Å—Ç

    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫
    for sheet_name in PROCESSING_ORDER:
        resource_class = RESOURCE_MAPPING[sheet_name]
        resource = resource_class()

        # –ü–æ–ª—É—á–∞–µ–º queryset –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        if sheet_name == '–°—Ç—Ä—É–∫—Ç—É—Ä–∞':
            queryset = Position.objects.all()
        elif sheet_name == '–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏':
            queryset = Employee.objects.all()
        elif sheet_name == '–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ':
            queryset = Equipment.objects.all()
        else:
            continue

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞)
        if organization:
            queryset = queryset.filter(organization=organization)

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        if sheet_name == '–°—Ç—Ä—É–∫—Ç—É—Ä–∞':
            queryset = queryset.select_related('organization', 'subdivision', 'department')
        elif sheet_name == '–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏':
            queryset = queryset.select_related('organization', 'subdivision', 'department', 'position')
        elif sheet_name == '–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ':
            queryset = queryset.select_related('organization', 'subdivision', 'department')

        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º dataset
        dataset = resource.export(queryset)

        # –°–æ–∑–¥–∞—ë–º –ª–∏—Å—Ç –≤ workbook
        ws = wb.create_sheet(title=sheet_name)

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        if dataset.headers:
            ws.append(dataset.headers)

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        for row in dataset:
            ws.append(row)

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ (–¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞)
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if cell.value:
                        max_length = max(max_length, len(str(cell.value)))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)  # –ú–∞–∫—Å–∏–º—É–º 50 —Å–∏–º–≤–æ–ª–æ–≤
            ws.column_dimensions[column_letter].width = adjusted_width

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ BytesIO
    output = BytesIO()
    wb.save(output)
    output.seek(0)

    return output.getvalue()
